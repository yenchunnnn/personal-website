---
title: Classifying depressed and healthy controls using motor activity time series data
author: Yen-Chun Chen
date: '2024-02-16'
slug: classifying-depressed-and-healthy-controls
categories:
  - Mechine Learning
  - R
tags:
  - Data Science
  - Classification
  - R Programming
  - Time Series
  - Clinical Psychology
subtitle: ''
summary: 'Applying machine-learning techniques to analyze motor activity patterns from depressed patients and healthy controls.'
authors: []
lastmod: '2024-02-16T12:59:04+08:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
output:
  blogdown::html_page:
    toc: true
---

## Introduction

Current practice of assessing mood episodes in Major Depression Disorders (MDD) largely depends on subjective observations combined with semi-structured clinical rating scales. Motor activity is an objective observation of the inner physiological state expressed in behavior patterns. Alterations of motor activity are essential features of MDD.

prevent at begining

The aim was to investigate if objective biological measures can aid existing diagnostic practice, by applying machine-learning techniques to analyze motor activity patterns from depressed patients and healthy controls.

## Preprocessing

```{r message=FALSE, warning=FALSE}
# Library package
library(tidyverse)
library(rsample)
library(caret)
library(vip)
library(tsfeatures)
```

### Setting up dataframe

Load actigraph files.

```{r include=FALSE}
condition_path <- 'C:/Users/User/Desktop/研究所課程 隨便看/機器學習/The depression dataset/condition'

control_path <- 'C:/Users/User/Desktop/研究所課程 隨便看/機器學習/The depression dataset/control'
```

```{r}
# condition files
condition_file <- list.files(path = condition_path, pattern = '*.csv', full.names = T)

# control files
control_file <- list.files(path = control_path, pattern = '*.csv', full.names = T)

# number of files
c(condition = length(condition_file), control = length(control_file))
```

Create condition data frame.

```{r message=FALSE}
# Change to UTC timezone
Sys.setlocale("LC_TIME", "C")

# read condition files
condition_data <- read_csv(condition_file, id = "ID") %>%
    mutate(ID = parse_number(ID),
           timestamp = as.POSIXct(str_replace_all(timestamp, "/", "-")),
           date = as.Date(str_replace_all(date, "/", "-")),
           group = 'condition')
glimpse(condition_data)
```

Create control data frame.

```{r message=FALSE}
# read control files
control_data <- read_csv(control_file, id = "ID") %>%
    mutate(ID = parse_number(ID) + 23,
           group = 'control')
glimpse(control_data)
```

Merge two data frames.

```{r}
# combine control and condition data
full_df <- rbind(condition_data, control_data) %>%
    mutate(group = as.factor(group))

head(full_df)
```

Notice that this is a multilevel data frame

```mermaid
graph TD
A[L5: groups] --> B[L4: subjects] --> C[L3: dates] --> D[L2: hours] --> E[L1: minutes]

```

### Cleaning data

Visualize data to see overall patterns.

```{r}
# nest by ID
nest_df <- full_df %>%
    group_by(ID) %>%
    nest() %>%
    arrange(ID)

# plot function
plot_fun <- function(df) {
    ggplot(df, aes(timestamp, activity)) +
        geom_line() +
        theme(axis.text.x = element_blank())
}

# create plot columns
nest_df <- nest_df %>%
    mutate(plot = map(data, plot_fun))

# condition plots
grid.arrange(grobs = nest_df$plot[1:23], ncol = 4)

# control plots, cause it's too many plots if we put all of them in one figure,
# we'll separate plotting them
grid.arrange(grobs = nest_df$plot[24:39], ncol = 4)
grid.arrange(grobs = nest_df$plot[40:55], ncol = 4)
```

It seems like some of days subjects didn't record activity, so we'll have to remove those days. We'll remove every day with sub-threshold activity (threshold = 25). In this way, we'll preserve whitin day variability.

```{r}
# filter where doesn't fit threshold
clean_df <- full_df %>%
    group_by(ID, date) %>%
    mutate(mean_perday = mean(activity)) %>%
    # mean activity per day threshold: 25
    filter(mean_perday > 25)

# see the rows difference
list(full = dim(full_df), clean_subact = dim(clean_df))
```

There may be some days that's not completed record for 24 hr, which means fewer than 24\*60 = 1440 mins.

```{r}
# check if there any days that's < 1440 mins
clean_df %>% 
    group_by(ID, date) %>%
    count() %>%
    filter(n < 1440)
```

```{r}
# remove the rows that's not completed
clean_df <- clean_df %>%
    group_by(ID, date) %>%
    mutate(minutes = length(timestamp)) %>%
    filter(minutes == 1440)

# see the difference
list(full = dim(full_df), clean_comact = dim(clean_df))
```

## Exploratory Data Analysis

### Summarizing days by group

```{r}
# summary of the days between groups
day_df <- clean_df %>% 
    group_by(ID) %>% 
    summarise(day = length(unique(date))) %>%
    mutate(group = as.factor(ifelse(ID <= 23, 'condition', 'control')))

psych::describeBy(day_df, group = day_df$group)
```

```{r}
# sum of days
day_df %>% 
    group_by(group) %>%
    summarise(count = sum(day))
```

|       | Condition | Control |
|-------|-----------|---------|
| total | 329       | 463     |
| mean  | 14.30     | 14.47   |
| sd    | 1.79      | 1.41    |
| min   | 10        | 13      |
| max   | 19        | 21      |

: Descriptive statistics of collected days by group

### Activity between groups

We majorly choose three statistical features that extracted from date level (L3) in this step.

Which are:

- Mean activity within a day

- standard deviation of activity within a day

- The proportion of minutes with an activity level of zero within a day

We may hypothesis that condition group would have lower mean activity, higher variety of activity, and higer zero activity of proportion in a day, compare to control group.

#### Overall 24hr span

Because the activity isn't normal distribution, we have to normalize it before further calculation. Here we use log transformation to adjust skewness.

```{r}
# calculate mean activity after log transform
clean_df <- clean_df %>% 
    group_by(ID, date) %>% 
    mutate(log_activity = log(activity + 1),
           mean_activity = mean(log_activity),
           sd_activity = sd(log_activity), # sd for per day per person
           zero_prop = zero_proportion(log_activity))

# select needed columns and filter rows
group_act <- clean_df %>%
    select(ID, group, date, mean_activity, sd_activity, zero_prop) %>%
    distinct() 

# box plot for this three vars
reshape2::melt(group_act[, c(2, 4:6)], id.vars="group") %>%
    # Everything on the same plot
    ggplot(., aes(group, value, col = variable)) + 
      geom_boxplot()
```

It seems like there're still remaining noisy activity even though we've already log transformed data.

```{r}
# summarise group activity
group_act %>%
    group_by(group) %>%
    summarise(mean = mean(mean_activity),
              sd = mean(sd_activity),
              zero_prop = mean(zero_prop))
```

The descriptive statistic looks make sense, expect for the variance. Let's see if the differences are significant or not.

```{r}
# test for homogeneity in variances
car::leveneTest(mean_activity ~ group, data = group_act)
car::leveneTest(sd_activity ~ group, data = group_act)
car::leveneTest(zero_prop ~ group, data = group_act)
```

Since the inhomogeneous variance, so we have to set `var.equal = FALSE` for mean and zero proportion, and `var.equal = TRUE` for sd.

```{r}
# corresponding two sample t-test

# mean: condition less than control
t.test(mean_activity ~ group, data = group_act, alternative = "less", var.equal = FALSE)

# sd: condition greater than control
t.test(sd_activity ~ group, data = group_act, alternative = "greater", var.equal = TRUE)

# zero proportion: condition greater than control
t.test(zero_prop ~ group, data = group_act, alternative = "greater", var.equal = FALSE)
```

|                 | Condition | Control |             |
|-----------------|-----------|---------|-------------|
| mean            | 2.80      | 3.44    | *p \< .001* |
| sd              | 2.50      | 2.63    | *p = 1*     |
| zero proportion | 0.41      | 0.32    | *p \< .001* |

: Characteristics of the depressed patients and healthy controls in 24hr activity

#### Under hourly span

The activity were normalized (range: 0-1) across both groups to make them comparable. Here we'll use the heat map and line graph to compare activities between groups by hours.

```{r message=FALSE, warning=FALSE}
# add normal and hour columns
clean_df <- clean_df %>%
    mutate(normal_zerone = scales::rescale(log_activity),
           hour = hour(timestamp))

# heat map
heat_plot <- clean_df %>%
    group_by(group, hour) %>%
    summarise(activity = mean(normal_zerone)) %>%
    ggplot(., aes(group, hour, fill = activity)) + 
        geom_tile() +
        scale_fill_gradient(low = "white", high = "blue")

# line plot
line_plot <- clean_df %>%
    group_by(group, hour) %>%
    summarise(activity = mean(normal_zerone)) %>%
    ggplot(., aes(hour, activity, color = group)) +
        geom_line()

grid.arrange(heat_plot, line_plot, ncol = 1)
```

It's interesting that control group have a opposite circadian rhythms as we thought. But we can see from the heat map that condition group may have a slightly lower activity compare to control group.

## Modeling

### Feature extraction

Beside of mean, standard deviation, and zero proportion of activity, we'll extract other features based on previous studies.

```{r message=FALSE, warning=FALSE}
# set up final features df for ML
feature_df <- clean_df %>%
    group_by(ID, date) %>%
    summarise(
        mean_act = mean(log_activity),
        sd_act = sd(log_activity), 
        zero_prop = zero_proportion(log_activity),
        # Coefficient of variation
        cv_act = sd_act / mean_act, 
        skew_act = psych::skew(log_activity),
        kurtosi_act = psych::kurtosi(log_activity),
        max_act = max(log_activity),
        q99_act = quantile(log_activity, probs = 0.99),
        q75_act = quantile(log_activity, probs = 0.75),
        q25_act = quantile(log_activity, probs = 0.25),
        med_act = median(log_activity),
        #  number of times a time series crosses the median line
        cross_medpoint = crossing_points(log_activity)
    ) %>%
    distinct() %>%
    mutate(group = as.factor(if_else(ID < 24, "condition", "control"))) %>%
    ungroup() %>%
    select(-c("ID", "date"))

feature_df
```


### Splitting train/test set

Create a single 70/30 split of the data.

```{r}
set.seed(123)

# split train/test
split_data <- initial_split(feature_df, prop = 0.7, strata = 'group')
train_set <- training(split_data)
test_set <- testing(split_data)

# see prop
list(train_num = table(train_set$group),
     train_prop = table(train_set$group) %>% prop.table(), 
     test_num = table(test_set$group),
     test = table(test_set$group) %>% prop.table())
```

### Training models

Baseline model: logistic regression

Comparison model: random forest, gradient boosting

```{r}
set.seed(123)

# Create reusable trainControl
myControl <- trainControl(
  summaryFunction = twoClassSummary,
  classProbs = TRUE, 
  verboseIter = FALSE,
  savePredictions = TRUE,
  index = createFolds(train_set$group, k = 5)
)
```

#### Logistic regression

```{r}
# train logistic model
model_logis <- train(
    x = train_set[, -13],
    y = train_set$group,
    metric = "ROC",
    method = "glm",
    trControl = myControl,
    preProcess = c("center", "scale")
)

model_logis
```

```{r}
# predict on training set
confusionMatrix(predict(model_logis, train_set), train_set$group)
```

```{r}
# predict on testing set
p_logis <- predict(model_logis, test_set)
confusionMatrix(p_logis, test_set$group)
```

#### Random forest

```{r warning=FALSE}
# train random forest
model_rf <- train(
    x = train_set[, -13],
    y = train_set$group,
    metric = "ROC",
    method = "ranger",
    trControl = myControl,
    preProcess = c("center", "scale"),
    tuneGrid = expand.grid(mtry = 1:6,
                           splitrule = 'extratrees',
                           min.node.size = c(1, 5, 10, 15, 20))
)

model_rf
```


```{r}
# predict on training set
confusionMatrix(predict(model_rf, train_set), train_set$group)
```

```{r}
# predict on testing set
p_rf <- predict(model_rf, test_set)
confusionMatrix(p_rf, test_set$group)
```

#### Gradient boosting 

```{r warning=FALSE}
# train random forest
model_sgb <- train(
    x = train_set[, -13],
    y = train_set$group,
    metric = "ROC",
    method = "gbm",
    trControl = myControl,
    preProcess = c("center", "scale"),
    tuneGrid = expand.grid(interaction.depth = 1:6,
                           shrinkage = 0.1,
                           n.trees = c(50,100,150),
                           n.minobsinnode = c(10, 15, 20)),
    verbose = F
)

model_sgb
```


```{r}
# predict on training set
confusionMatrix(predict(model_sgb, train_set), train_set$group)
```

```{r}
# predict on testing set
p_sgb <- predict(model_sgb, test_set)
confusionMatrix(p_sgb, test_set$group)
```


### Comparing models

#### Metrics for evaluation

```{r}
# Create model_list
model_list <- list(logistic = model_logis, rf = model_rf, sgb = model_sgb)

# Pass model_list to resamples
resamples <- resamples(model_list)

# Summarize the results
summary(resamples)
```

```{r}
# Create bwplot, roc
bwplot(resamples, metric = "ROC")
```


```{r}
# Create bwplot, Sens
bwplot(resamples, metric = "Sens")
```


```{r}
# Create bwplot, Spec
bwplot(resamples, metric = "Spec")
```

It seems like logistic regression would be the best model to classify depressed and control group on this data.

## Conclusion

Testing set performance, add table here!


```{r}
# feature importance in logistic model
vip(model_logis, num_features = 12)
```






