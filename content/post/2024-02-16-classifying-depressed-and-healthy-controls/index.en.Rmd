---
title: Classifying depressed and control groups by motor activity time series data
author: Yen-Chun Chen
date: '2024-02-16'
slug: classifying-depressed-and-healthy-controls
categories:
  - R
  - Mechine Learning
tags:
  - Data Science
  - Classification
  - R Programming
  - Time Series
  - Clinical Psychology
subtitle: ''
summary: 'Applying logistic regression, random forest, and SVM to analyze the daily motor activity patterns of participants.'
authors: []
lastmod: '2024-02-16T12:59:04+08:00'
featured: no
image:
  caption: 'Friends scenes from NBC'
  focal_point: 'smart'
  preview_only: no
projects: []
output:
  blogdown::html_page:
    toc: true
---

## Introduction

Depressive disorders is a cluster of mental disorders characterized by the presence of sad, empty, or irritable mood, accompanied by somatic and cognitive changes that significantly affect the individual's capacity to function. [^1]

[^1]: American Psychiatric Association. (2013). Diagnostic and statistical manual of mental disorders (5th ed.). <https://doi.org/10.1176/appi.books.9780890425596>

The traditional practice of assessing depressed mood states largely depends on subjective reports or observations made by others, combined with structured clinical rating scales. However, subjectiveness has the potential to lead to bias and misdiagnosis, which will affect the recovery and subsequent treatment as well as intervention. Therefore, when making a clinical diagnosis, several objective indicators may be taken into account.

Alteration of motor activity (psychomotor) is one of the diagnostic criteria in depressive disorders. The depressive state is often associated with lower mean activity, higher intraindividual variability, and less complexity in activity patterns when compared to healthy controls. [^2] [^3] And wearable technology-based ecological momentary assessment allows us to collect objective and real-time data on participants' daily motor activity.

[^2]: Burton, C., McKinstry, B., Szentagotai Tătar, A., Serrano-Blanco, A., Pagliari, C., & Wolters, M. (2013). Activity monitoring in patients with depression: a systematic review. *Journal of affective disorders, 145(1)*, 21--28. <https://doi.org/10.1016/j.jad.2012.07.001>

[^3]: Krane-Gartiser, K., Henriksen, T. E., Vaaler, A. E., Fasmer, O. B., & Morken, G. (2015). Actigraphically assessed activity in unipolar depression: a comparison of inpatients with and without motor retardation. *The Journal of clinical psychiatry, 76(9)*, 1181--1187. <https://doi.org/10.4088/JCP.14m09106>

So the aim of this project was to investigate whether objective biological metrics may improve on traditional diagnosis procedures by analyzing motor activity patterns in both healthy and depressed participants using machine learning techniques.

## Preprocessing

```{r message=FALSE, warning=FALSE}
# Library package
library(tidyverse)
library(rsample)
library(caret)
library(vip)
library(tsfeatures)
```

### Setting up dataframe

**Data description**

The Depresjon dataset is a collection of data that includes the motor activity of participants measured with a wrist-worn actigraph.[^4] The sampling frequency is 32Hz and movements greater than 0.05g are recorded. The number of counts corresponds to the intensity of the movement. Total activity counts were continually recorded at one-minute intervals. The following files contain:

[^4]: Garcia-Ceja, E., Riegler, M., Jakobsen, P., Torresen, J., Nordgreen, T., Oedegaard, K. J., & Fasmer, O. B. (2018). DEPRESJON dataset [Data set]. Zenodo. <https://doi.org/10.5281/zenodo.1219550>

``` markmap{height="200px"}
- Depresjon dataset
  - Condition: 23 depressed participants
    - timestamp (one minute intervals)
    - date (date of measurement): inconsistency for every participant.
    - activity
  - Control: 32 healthy participants
    - timestamp (one minute intervals)
    - date (date of measurement): inconsistency for every participant.
    - activity
  - Scores: all participants
    - Demographic
    - Severity of depression
```

We only used actigraph data in this analysis.

```{r include=FALSE}
condition_path <- 'C:/Users/User/Desktop/研究所課程 隨便看/機器學習/The depression dataset/condition'

control_path <- 'C:/Users/User/Desktop/研究所課程 隨便看/機器學習/The depression dataset/control'

# Change to UTC timezone
Sys.setlocale("LC_TIME", "C")
```

```{r}
# Load actigraph files

# condition files
condition_file <- list.files(path = condition_path, pattern = '*.csv', full.names = T)

# control files
control_file <- list.files(path = control_path, pattern = '*.csv', full.names = T)

# number of files
c(condition = length(condition_file), control = length(control_file))
```

Create a condition data frame.

```{r message=FALSE}
# read condition files
condition_data <- read_csv(condition_file, id = "ID") %>%
    mutate(ID = parse_number(ID),
           timestamp = as.POSIXct(str_replace_all(timestamp, "/", "-")),
           date = as_date(str_replace_all(date, "/", "-")),
           group = 'condition')
glimpse(condition_data)
```

Create a control data frame.

```{r message=FALSE}
# read control files
control_data <- read_csv(control_file, id = "ID") %>%
    mutate(ID = parse_number(ID) + 23,
           group = 'control')
glimpse(control_data)
```

Merge two data frames.

```{r}
# combine control and condition data
full_df <- rbind(condition_data, control_data) %>%
    mutate(group = as.factor(group))

head(full_df)
```

Notice that this is a multilevel data frame:

-   Level 5: group

-   Level 4: subject

-   Level 3: date

-   Level 2: hour

-   Level 1: minute

### Cleaning data

Visualize the data to see overall patterns.

```{r}
# nest by ID
nest_df <- full_df %>%
    group_by(ID) %>%
    nest() %>%
    arrange(ID)

# plot function
plot_fun <- function(df) {
    ggplot(df, aes(timestamp, activity)) +
        geom_line() +
        theme(axis.text.x = element_blank())
}

# create plot columns
nest_df <- nest_df %>%
    mutate(plot = map(data, plot_fun))

# condition plots
grid.arrange(grobs = nest_df$plot[1:23], ncol = 4)

# control plots, cause it's too many plots if we put all of them in one figure,
# we'll separate plotting them
grid.arrange(grobs = nest_df$plot[24:39], ncol = 4)
grid.arrange(grobs = nest_df$plot[40:55], ncol = 4)
```

It appears that there were days when subjects did not record activities; thus, we must delete those days. Mean activity of a day that lower than the threshold (threshold = 25) was removed. In this sense, we should preserve within-day variability.

```{r}
# filter days where doesn't fit threshold
clean_df <- full_df %>%
    group_by(ID, date) %>%
    mutate(mean_perday = mean(activity)) %>%
    # mean activity per day threshold: 25
    filter(mean_perday > 25)

# see the rows difference
list(full = dim(full_df), clean_subact = dim(clean_df))
```

There may be some days that's not a record for 24 hours, which means fewer than 24\*60 = 1440 minutes.

```{r}
# check if there any day that's < 1440 mins
clean_df %>% 
    group_by(ID, date) %>%
    count() %>%
    filter(n < 1440)
```

```{r}
# remove the rows that's not completed
clean_df <- clean_df %>%
    group_by(ID, date) %>%
    mutate(minutes = length(timestamp)) %>%
    filter(minutes == 1440)

# see the difference
list(full = dim(full_df), clean_comact = dim(clean_df))
```

## Exploratory Data Analysis

### Day between groups

```{r}
# summary of the days between groups
day_df <- clean_df %>% 
    group_by(ID) %>% 
    summarise(day = length(unique(date))) %>%
    mutate(group = as.factor(ifelse(ID <= 23, 'condition', 'control')))

psych::describeBy(day_df$day, group = day_df$group)
```

```{r}
# sum of days
day_df %>% 
    group_by(group) %>%
    summarise(count = sum(day))
```

|       | Condition | Control |
|-------|-----------|---------|
| total | 329       | 463     |
| mean  | 14.30     | 14.47   |
| sd    | 1.79      | 1.41    |
| min   | 10        | 13      |
| max   | 19        | 21      |

: Descriptive statistics of collected days by group

### Activity between groups

#### Overall 24-hour span

We primarily chose three statistical features that were extracted from the *date level* in this step.[^5] [^6]

[^5]: Garcia-Ceja, E., Riegler, M., Jakobsen, P., Tørresen, J., Nordgreen, T., Oedegaard, K.J., & Fasmer, O.B. (2018). Depresjon: a motor activity database of depression episodes in unipolar and bipolar patients. *Proceedings of the 9th ACM Multimedia Systems Conference.*

[^6]: Jakobsen, P., Garcia-Ceja, E., Riegler, M., Stabell, L. A., Nordgreen, T., Torresen, J., Fasmer, O. B., & Oedegaard, K. J. (2020). Applying machine learning in motor activity time series of depressed bipolar and unipolar patients compared to healthy controls. *PloS one, 15(8),* e0231995. <https://doi.org/10.1371/journal.pone.0231995>

Which are:

-   Mean activity

-   Standard deviation of activity

-   The proportion of minutes with an activity level of zero within a day

Based on previous studies, we may hypothesize that the condition group would have *lower mean activity*, a *higher variability of activity*, and a *higher zero activity of proportion* in a day compared to the control group.

Because the activity isn't a normal distribution (e.g., condition group would have more low activity levels than high activity levels), we have to normalize it before further calculation. Here we used log transformation to adjust skewness.

```{r}
# calculate mean activity after log transform
clean_df <- clean_df %>% 
    group_by(ID, date) %>% 
    mutate(log_activity = log(activity + 1),
           mean_activity = mean(log_activity),
           sd_activity = sd(log_activity), 
           zero_prop = zero_proportion(log_activity))

# select needed columns and filter rows
group_act <- clean_df %>%
    select(ID, group, date, mean_activity, sd_activity, zero_prop) %>%
    distinct() 

# box plot for this three vars
reshape2::melt(group_act[, c(2, 4:6)], id.vars = "group") %>%
    # Everything on the same plot
    ggplot(., aes(group, value, col = variable)) + 
      geom_boxplot()
```

It seems like there's still some noisy (outlier) activity, even though we've already log transformed data.

```{r}
# summarise group activity
group_act %>%
    group_by(group) %>%
    summarise(mean = mean(mean_activity),
              sd = mean(sd_activity),
              zero_prop = mean(zero_prop))
```

The descriptive statistics make sense; expect for the variability. Let's see if the differences are significant or not.

```{r}
# test for homogeneity in variances
car::leveneTest(mean_activity ~ group, data = group_act)
car::leveneTest(sd_activity ~ group, data = group_act)
car::leveneTest(zero_prop ~ group, data = group_act)
```

Since there are inhomogeneous variances, we have to set `var.equal = FALSE` for mean and zero proportion and `var.equal = TRUE` for standard deviation.

```{r}
# corresponding two sample t-test

# mean: condition less than control
t.test(mean_activity ~ group, data = group_act, alternative = "less", var.equal = FALSE)

# sd: condition greater than control
t.test(sd_activity ~ group, data = group_act, alternative = "greater", var.equal = TRUE)

# zero proportion: condition greater than control
t.test(zero_prop ~ group, data = group_act, alternative = "greater", var.equal = FALSE)
```

|                 | Condition | Control |             |
|-----------------|-----------|---------|-------------|
| mean            | 2.80      | 3.44    | *p \< .001* |
| sd              | 2.50      | 2.63    | *p = 1*     |
| zero proportion | 0.41      | 0.32    | *p \< .001* |

: Characteristics of the depressed patients and healthy controls in 24-hour activity

#### Under an hourly span

The activity was normalized (range: 0-1) across both groups to make them comparable. Here we'll use the heat map and line graph to compare activities between groups by hours.

```{r message=FALSE, warning=FALSE}
# add normal and hour columns
clean_df <- clean_df %>%
    mutate(normal_zerone = scales::rescale(log_activity),
           hour = hour(timestamp))

# heat map
heat_plot <- clean_df %>%
    group_by(group, hour) %>%
    summarise(activity = mean(normal_zerone)) %>%
    ggplot(., aes(group, hour, fill = activity)) + 
        geom_tile() +
        scale_fill_gradient(low = "white", high = "blue")

# line plot
line_plot <- clean_df %>%
    group_by(group, hour) %>%
    summarise(activity = mean(normal_zerone)) %>%
    ggplot(., aes(hour, activity, color = group)) +
        geom_line()

grid.arrange(heat_plot, line_plot, ncol = 1)
```

It's interesting that the control group has an opposite circadian rhythm as we thought. But we can see from the heat map that the condition group may have slightly lower activity compared to the control group.

## Modeling

### Feature extraction

Besides the mean, standard deviation, and zero proportion of activity, we extracted other features according to previous studies.[^7] Including:

[^7]: Zanella-Calzada, L. A., Galván-Tejada, C. E., Chávez-Lamas, N. M., Gracia-Cortés, M. D. C., Magallanes-Quintanar, R., Celaya-Padilla, J. M., Galván-Tejada, J. I., & Gamboa-Rosales, H. (2019). Feature Extraction in Motor Activity Signal: Towards a Depression Episodes Detection in Unipolar and Bipolar Patients. *Diagnostics (Basel, Switzerland), 9(1),* 8. <https://doi.org/10.3390/diagnostics9010008>

-   Coefficient of variation

-   Kurtosis

-   Skewness

-   Quantile 25, 75, 95, 99

-   Median

-   Number of times a time series crosses the median line

```{r message=FALSE, warning=FALSE}
# set up final features df for ML
feature_df <- clean_df %>%
    group_by(ID, date) %>%
    summarise(
        mean_act = mean(log_activity),
        sd_act = sd(log_activity), 
        zero_prop = zero_proportion(log_activity),
        # Coefficient of variation
        cv_act = sd_act / mean_act, 
        skew_act = psych::skew(log_activity),
        kurtosi_act = psych::kurtosi(log_activity),
        q99_act = quantile(log_activity, probs = 0.99),
        q95_act = quantile(log_activity, probs = 0.95),
        q75_act = quantile(log_activity, probs = 0.75),
        q25_act = quantile(log_activity, probs = 0.25),
        med_act = median(log_activity),
        #  number of times crosses the median line
        cross_medpoint = crossing_points(log_activity)
    ) %>%
    distinct() %>%
    mutate(group = as.factor(if_else(ID < 24, "condition", "control"))) %>%
    ungroup() %>%
    select(-c("ID", "date"))

feature_df
```

### Splitting train/test set

Create a single 70/30 split of the data.

```{r}
set.seed(123)

# split train/test
split_data <- initial_split(feature_df, prop = 0.7, strata = 'group')
train_set <- training(split_data)
test_set <- testing(split_data)

# see prop
list(train_num = table(train_set$group),
     train_prop = table(train_set$group) %>% prop.table(), 
     test_num = table(test_set$group),
     test = table(test_set$group) %>% prop.table())
```

### Training models

Baseline model: logistic regression

-   Traditional two classes classification model

Comparison model: random forest, linear SVM

-   Linear SVM: had a higher model performance in past studies

-   Random forest: ensemble method; easier to explain

The evaluation of the results was done through a ROC curve-based approach.

```{r}
set.seed(123)

# Create reusable trainControl
myControl <- trainControl(
  summaryFunction = twoClassSummary,
  classProbs = TRUE, 
  verboseIter = FALSE,
  savePredictions = TRUE,
  index = createFolds(train_set$group, k = 5)
)
```

#### Logistic regression

```{r warning=FALSE}
# train logistic model
model_logis <- train(
    x = train_set[, -13],
    y = train_set$group,
    metric = "ROC",
    method = "glm",
    trControl = myControl,
    preProcess = c("center", "scale")
)

model_logis
```

#### Random forest

```{r warning=FALSE}
set.seed(125749)

# train random forest
model_rf <- train(
    x = train_set[, -13],
    y = train_set$group,
    metric = "ROC",
    method = "ranger",
    trControl = myControl,
    preProcess = c("center", "scale"),
    tuneGrid = expand.grid(mtry = 1:6,
                           splitrule = 'extratrees',
                           min.node.size = c(10, 15, 20, 25, 30)),
    importance = 'impurity'
)

model_rf
```

#### SVM

```{r warning=FALSE}
# train linear svm
model_svm <- train(
    # change to formula, avoiding kernlab class probability calculations failed
    group ~ .,        
    data = train_set,
    metric = "ROC",
    method = "svmLinear",
    trControl = myControl,
    preProcess = c("center", "scale"),
    tuneGrid = expand.grid(C = seq(1, 5, length = 20))
)

model_svm
```

Predict on training set.

```{r}
# Create model_list
model_list <- list(logistic = model_logis, rf = model_rf, svm = model_svm)

# predict on training set to see if it's overfitting later
for (i in 1:length(model_list)) {
    print(confusionMatrix(predict(model_list[[i]], train_set),
                          train_set$group))
}
```

### Validation

#### Metrics

-   AUC: Area Under ROC curve

-   Accuracy: the percentage of correctly classified condition and control samples.

-   Sensitivity: the fraction of correctly classified conditions related to all conditions.

-   Specificity: the fraction of controls correctly classified as controls.

-   Balanced Accuracy: the arithmetic mean of sensitivity and specificity, which is particularly useful when the two classes are imbalanced.

-   PPV: the proportion of true condition samples.

-   NPV: the proportion of true control samples.

```{r message=FALSE}
# gather metrics together
acc <- c()
bal <- c()
sen <- c()
spe <- c()
ppv <- c()
npv <- c()
auc <-c()

for (num in 1:length(model_list)) {
    prediction <- predict(model_list[[num]], test_set)
    confus <- confusionMatrix(prediction, test_set$group)
    acc <- acc %>% append(confus$overall[["Accuracy"]])
    bal <- bal %>% append(confus$byClass[["Balanced Accuracy"]])
    sen <- sen %>% append(confus$byClass[["Sensitivity"]])
    spe <- spe %>% append(confus$byClass[["Specificity"]])
    ppv <- ppv %>% append(confus$byClass[["Pos Pred Value"]])
    npv <- npv %>% append(confus$byClass[["Neg Pred Value"]])
    ROC <- pROC::roc(as.numeric(test_set$group), as.numeric(prediction))
    auc <- auc %>% append(pROC::auc(ROC))
}

metric <- data.frame(Model = c("Logistic", "Random Forest", "SVM"),
                     Accuracy = acc,
                     Balanced_ACC = bal, 
                     Sensitivity = sen,
                     Specificity = spe,
                     PPV = ppv,
                     NPV = npv,
                     AUC = auc) %>% 
    mutate(across(-1, ~ round(.x, 3)))

metric
```

Based on the measurements, we discovered that random forest have the highest balanced accuracy and AUC. But regardless of the model, they share the same high specificity and low sensitivity. This indicates that while our models performed well in categorizing control cases, they were less likely to accurately categorize condition cases.

#### Variable importance

Let's see the variable importance of the random forest model.

```{r}
# visualize rf
vip(model_rf, num_features = 12)
```

According to the figure, the five most important features in the random forest model were the median, zero proportion, mean, quantile 95, and skewness of daily activity.

## Conclusion

In conclusion, our investigation has demonstrated the potential of a number of machine learning algorithms to distinguish between depressed and healthy participants in time series of motor activity. Furthermore, random forest outperformed other methods in our analysis for the classification task. Additionally, the extracted statistical features indicated that the information they include describes the primary aspects of a participant's daily activities, making it possible to distinguish between depressed and healthy participants. Nevertheless, because of its limited sensitivity, we must integrate this kind of index with other indicators (e.g., clinical assessments) to get the big picture if we would like to implement it to aid in clinical diagnosis.
